{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c3045835Newcastle/2/blob/main/ML_Practical2_CV_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical 2\n",
        "\n",
        "## Preliminary\n",
        "\n",
        "Load the required libraries and set defaults"
      ],
      "metadata": {
        "id": "nIE9-BRo5IYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import (\n",
        "    LinearRegression,\n",
        "    LogisticRegression,\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    mean_squared_error,\n",
        "    r2_score,\n",
        ")\n",
        "from sklearn.model_selection import (\n",
        "    cross_val_score,\n",
        "    GridSearchCV,\n",
        "    train_test_split,\n",
        ")\n",
        "from sklearn.naive_bayes import (\n",
        "    GaussianNB,\n",
        "    MultinomialNB,\n",
        ")\n",
        "from sklearn.neighbors import (\n",
        "    KNeighborsClassifier,\n",
        "    KNeighborsRegressor,\n",
        ")\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import (\n",
        "    DecisionTreeClassifier,\n",
        "    plot_tree,\n",
        ")\n",
        "\n",
        "sns.set_theme()\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "D3LsvXm67XNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Validation Approaches"
      ],
      "metadata": {
        "id": "E0RpYViR2V74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will explore the use of the validation set approach in order to estimate the test error rates that result from fitting various linear models on the `Auto` data set.\n",
        "\n",
        "We use the function `train_test_split()` to split the data into training and validation sets. As there are $392$ observations, we split into two equal sets of size $196$ using the argument `test_size=196`.\n",
        "\n",
        "It is generally a good idea to set a random seed when performing operations like this that contain an element of randomness, so that the results obtained can be reproduced precisely at a later time. We set the random seed of the splitter with the argument `random_state=seed`."
      ],
      "metadata": {
        "id": "H2kw52KXAS_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data set\n",
        "path = 'https://github.com/vladoxNCL/ml_course/raw/main/Auto.csv'\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "# change horsepower type to float and fix missing values\n",
        "df['horsepower'] = df['horsepower'].replace('?', np.nan)\n",
        "df['horsepower'] = df['horsepower'].astype(float)\n",
        "hp_median = df['horsepower'].median()\n",
        "df['horsepower'] = df['horsepower'].fillna(hp_median)\n",
        "\n",
        "# add quadratic hp feature\n",
        "df['horsepower^2'] = df['horsepower'] ** 2"
      ],
      "metadata": {
        "id": "WgvssbBE2YJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can fit a linear regression using only the observations corresponding to the training set `df_train`:"
      ],
      "metadata": {
        "id": "xgnJATnrBGjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = ['horsepower', 'horsepower^2']\n",
        "response = 'mpg'\n",
        "reg = LinearRegression()\n",
        "\n",
        "# split data into training and validation\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    df[predictors],\n",
        "    df[response],\n",
        "    test_size=196,\n",
        "    random_state=seed,\n",
        ")\n",
        "\n",
        "reg.fit(X_train, y_train)\n",
        "y_train_pred = reg.predict(X_train)\n",
        "y_valid_pred = reg.predict(X_valid)\n",
        "\n",
        "print(f'Training MSE: {mean_squared_error(y_train, y_train_pred)}')\n",
        "print(f'Validation MSE: {mean_squared_error(y_valid, y_valid_pred)}')"
      ],
      "metadata": {
        "id": "o8jYJUcuBF4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-Validation\n",
        "\n",
        "Lets now check the MSE using 5-Fold, 10-Fold, and Leave-One-Out (LOO) cross-validation.\n",
        "\n",
        "For this, we will use `sklearn`'s `cross_val_score()` function:"
      ],
      "metadata": {
        "id": "4taZ3x4IE7Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folds = {\n",
        "    '5-Fold': 5,\n",
        "    '10-Fold': 10,\n",
        "    'LOO': df.shape[0],\n",
        "}\n",
        "\n",
        "for key, val in folds.items():\n",
        "    scores = cross_val_score(\n",
        "        reg, df[predictors], df[response],\n",
        "        cv=val, scoring='neg_mean_squared_error',\n",
        "    )\n",
        "    print(f'{key}-Fold MSE: {-scores.mean()}')"
      ],
      "metadata": {
        "id": "HeMmcYMxEO7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CV approach gives a better estimation of real-world test performance, as all of the data is being utilised."
      ],
      "metadata": {
        "id": "GP9avqUOE2fR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Hands On\n",
        "\n",
        "For the `Credit` data set, predict `Balance` from the remaining features using KNN regression. Some of these features are categorical, and will need to be (one-hot) encoded first.\n",
        "\n",
        "Use **5-Fold cross-validation** to find the best $K \\in \\{1, 2, \\dots, 10\\}$ with respect to **R^2 Score**."
      ],
      "metadata": {
        "id": "Ebsuoc-KGonK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'https://github.com/vladoxNCL/ml_course/raw/main/Credit.csv'\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "# your code here"
      ],
      "metadata": {
        "id": "NJpVIT41Gmo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Classification\n",
        "\n",
        "In class, we learnt about a few different classification models:\n",
        "\n",
        "1. Logistic regression\n",
        "2. KNN\n",
        "3. Na√Øve Bayes\n",
        "4. Decision trees\n",
        "5. Ensemble methods (e.g., random forests)\n",
        "6. SVCs\n",
        "\n",
        "Lets compare their performance on the `Default` dataset to predict `default` from `student`, `balance`, and `income`, using 5-Fold CV to select the best model.\n"
      ],
      "metadata": {
        "id": "1WbKb0SX6dPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'https://github.com/vladoxNCL/ml_course/raw/main/Default.csv'\n",
        "\n",
        "df = pd.read_csv(path)\n",
        "for col in ['default', 'student']:\n",
        "    df[col] = df[col].map({'No': 0, 'Yes': 1})\n",
        "df.head()"
      ],
      "metadata": {
        "id": "FPDGDNdjLBFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = ['student', 'balance', 'income']\n",
        "response = 'default'\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[preds],\n",
        "    df[response],\n",
        "    test_size=0.1,\n",
        "    random_state=seed,\n",
        ")\n",
        "\n",
        "clfs = {\n",
        "    'LR': make_pipeline(StandardScaler(), LogisticRegression(random_state=seed)),\n",
        "    'KNN': make_pipeline(StandardScaler(), KNeighborsClassifier()),\n",
        "    'GNB': make_pipeline(StandardScaler(), GaussianNB()),\n",
        "    'DT': DecisionTreeClassifier(random_state=seed),\n",
        "    'RF': RandomForestClassifier(random_state=seed),\n",
        "    'SVC': make_pipeline(StandardScaler(), SVC(random_state=seed)),\n",
        "}\n",
        "\n",
        "for clf_name, clf in clfs.items():\n",
        "    scores = cross_val_score(\n",
        "        clf, X_train, y_train,\n",
        "        cv=5, scoring='accuracy',\n",
        "    )\n",
        "    clf.fit(X_train, y_train)\n",
        "    preds = clf.predict(X_test)\n",
        "    accu = accuracy_score(y_test, preds)\n",
        "    print(f'{clf_name} Accuracy\\t Train CV: {scores.mean():.3f}\\t Test: {accu:.3f}')"
      ],
      "metadata": {
        "id": "OAg-Wc7WLfNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the models perform really well. However, the edge goes to **logistic regression**, since it is the most interpretable.\n",
        "\n",
        "\n",
        "### Hyper-parameter tuning\n",
        "\n",
        "As an exercise, lets try to improve the accuracy of **random forests** and **SVMs** through hyper-parameter tuning:"
      ],
      "metadata": {
        "id": "6WOZgQ2gMgQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the model and hyperparameter grid\n",
        "rf_clf = RandomForestClassifier(random_state=seed)\n",
        "param_grid = {\n",
        "    'n_estimators': list(range(1, 10)),\n",
        "    'max_depth': list(range(1, 10)),\n",
        "}\n",
        "\n",
        "# perform cross-validation and hyperparameter tuning on the training set\n",
        "grid_search = GridSearchCV(rf_clf, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# evaluate the model on the test set\n",
        "y_pred = grid_search.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# best hyperparameters and cross-validation score\n",
        "print(f'Best Parameters: {grid_search.best_params_}')\n",
        "print(f'Best CV Score: {grid_search.best_score_}')\n",
        "print(f'Test Accuracy: {acc:.3f}')"
      ],
      "metadata": {
        "id": "-AgExl_RMYH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc_clf = make_pipeline(StandardScaler(), SVC(random_state=seed))\n",
        "param_grid = {\n",
        "    'svc__C': [0.001, 0.01, 0.1, 1, 10],\n",
        "    'svc__kernel': ['linear', 'rbf', 'poly'],\n",
        "}\n",
        "\n",
        "# perform cross-validation and hyperparameter tuning on the training set\n",
        "grid_search = GridSearchCV(svc_clf, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# evaluate the model on the test set\n",
        "y_pred = grid_search.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Best hyperparameters and cross-validation score\n",
        "print(f'Best Parameters: {grid_search.best_params_}')\n",
        "print(f'Best CV Score: {grid_search.best_score_}')\n",
        "print(f'Test Accuracy: {acc:.3f}')"
      ],
      "metadata": {
        "id": "s1UkxbMF8F0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper-parameter tuning improved the performance of both RF and SVC. However, their performance didn't match **logistic regression**, which should still be preferred due to its interpretability.\n",
        "\n",
        "Lets see what info we can get from the LR model:"
      ],
      "metadata": {
        "id": "2cDmhMkaWfoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(random_state=seed)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print('Coefficients:')\n",
        "for feat, coef in zip(X_test.columns, clf.coef_[0]):\n",
        "    print(f'{feat}: {coef:.3f}')"
      ],
      "metadata": {
        "id": "vPDYP2Lj-KqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tells us that `student` is **negatively** correlated with defaulting, while `balance` is **positively** correlated with defaulting (although to a lesser extent), and `income` is *uncorrelated* with defaulting.\n",
        "\n",
        "Another explainable model is generated by decision trees:"
      ],
      "metadata": {
        "id": "iP6xcVf3_fzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier(max_depth=3, random_state=seed)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "print(f'Decision Tree Accuracy: {accuracy_score(y_test, preds)}\\n')\n",
        "\n",
        "imps = clf.feature_importances_\n",
        "print('Feature Importances:')\n",
        "for feat, imp in zip(X_train.columns, imps):\n",
        "    print(f'{feat}\\t {imp:.4f}')\n",
        "print('')\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plot_tree(clf, feature_names=X_train.columns, filled=True);"
      ],
      "metadata": {
        "id": "XX-EnoNDAFZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this model, `balance` is the most important feature, followed by `income` and finally `student` is not important.\n",
        "\n",
        "The colours in the plot represent the **classes**: *red* means $0$ (don't default) and *blue* means $1$ (default)."
      ],
      "metadata": {
        "id": "l0ERBuJwBPix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hands On\n",
        "\n",
        "Use the *Wine* dataset from scikit-learn and the Support Vector Classifier (SVC) model to perform 10-fold cross-validation.\n",
        "\n",
        "1. Load the Wine dataset from *scikit-learn*.\n",
        "2. Train/test split your data with a 90/10 proportion.\n",
        "3. Create an SVC classifier.\n",
        "4. Perform 10-fold cross-validation on the *training* data.\n",
        "5. Print the cross-validation scores and the mean score.\n",
        "6. Use the `GridSearchCV` function to tune the `'C'`, `'kernel'`, `'gamma'`, and `'degree'` hyper-parameters.\n",
        "7. Verify the quality of the resulting hyper-parameters over the *test* data."
      ],
      "metadata": {
        "id": "crxgOFYYU24a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wine = load_wine()\n",
        "wine.keys()\n",
        "\n",
        "# your code here"
      ],
      "metadata": {
        "id": "1ftBi58ANuuE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}